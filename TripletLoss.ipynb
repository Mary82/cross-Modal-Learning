{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TripletLoss.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mary82/cross-Modal-Learning/blob/master/TripletLoss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Azocbs8FI4s1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D,Input\n",
        "from keras import regularizers\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "import numpy as np\n",
        "import keras.backend as K\n",
        "from keras.models import Model\n",
        "from keras.layers.core import Lambda\n",
        "from keras.optimizers import Adam\n",
        "import random\n",
        "import itertools\n",
        "from keras.models import model_from_json\n",
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/gdrive')\n",
        "os.chdir('/content/gdrive/My Drive/Colab Notebooks/')\n",
        "from TripletLoss_utils import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0GAGbR2pJaLp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "41b9b0f0-4bd6-4692-bf3b-b409e5ec37ff"
      },
      "cell_type": "code",
      "source": [
        "num_classes = 100\n",
        "json_file = open('Models/cifar_model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "cifar_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "cifar_model.load_weights(\"Models/CIFAR100_Weight.h5\")\n",
        "print(\"Loaded model from disk\")\n",
        "cifar_model.summary()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 128)       3584      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 30, 30, 128)       147584    \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 30, 30, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 15, 15, 256)       295168    \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 15, 15, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 13, 13, 256)       590080    \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 13, 13, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 6, 6, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 6, 6, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              2098176   \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 100)               102500    \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 100)               0         \n",
            "=================================================================\n",
            "Total params: 6,777,060\n",
            "Trainable params: 6,777,060\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5lCENe5YNbZ7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Xs, Ys = load_cifar_flatten(cifar_model,num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "66og6Q6dQPrK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba37c836-727e-42d1-f5c3-45da64ed9dc5"
      },
      "cell_type": "code",
      "source": [
        "print Xs.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 2048)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "I0oO42-wWgTi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_model_tpl(n_in):\n",
        "    X_input = Input(n_in)\n",
        "    X = Dense(512, activation='relu', name = 'dense_layer_1')(X_input)\n",
        "    X = BatchNormalization(name = 'Batch_layer_1')(X)\n",
        "    X = Dropout(.2)(X)\n",
        "    X = Dense(128, name='dense_layer_2')(X)\n",
        "    X = Lambda(lambda  x: K.l2_normalize(x,axis=1))(X)\n",
        "    emb_model = Model(inputs = X_input, outputs = X, name = 'ImageEmb')\n",
        "    # load pre-trained weights into model\n",
        "    emb_model.load_weights(\"Models/img_emb_model.h5\")\n",
        "    \n",
        "    # anchor, positive, negative inputs\n",
        "    a = Input(shape = n_in)\n",
        "    p = Input(shape = n_in)\n",
        "    n = Input(shape = n_in)\n",
        "\n",
        "    a_emb = emb_model(a)\n",
        "    p_emb = emb_model(p)\n",
        "    n_emb = emb_model(n)\n",
        "\n",
        "    loss = Lambda(triplet_loss)([a_emb,p_emb, n_emb])\n",
        "    model = Model(inputs = [a, p, n], outputs = loss)\n",
        "\n",
        "    model.compile(loss=identity_loss, optimizer=Adam(0.000003), metrics = [accuracy])\n",
        "    return model, emb_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SlpnLG2i1rvs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d7bd4dc5-d19c-4dd2-bbba-4356a7d676e7"
      },
      "cell_type": "code",
      "source": [
        "# Create training data for triplet loss\n",
        "random.seed(1)\n",
        "subjects = np.unique(Ys).tolist()\n",
        "anchors_inds = []\n",
        "positives_inds = []\n",
        "labels = []\n",
        "train = random.sample(range(Xs.shape[0]),6000)\n",
        "test = list(set(range(Xs.shape[0])) - set(train))\n",
        "\n",
        "x_train = Xs[train]\n",
        "y_train = Ys[train]\n",
        "x_test = Xs[test]\n",
        "y_test = Ys[test]\n",
        "for subj in subjects:\n",
        "    mask = y_train == subj\n",
        "    inds = np.where(mask)[0]\n",
        "    for a, p in itertools.permutations(inds, 2):\n",
        "        a,p = random.sample(inds,2)\n",
        "        anchors_inds.append(a)\n",
        "        positives_inds.append(p)\n",
        "        labels.append(subj)\n",
        "\n",
        "anchors = x_train[anchors_inds]\n",
        "positives = x_train[positives_inds]\n",
        "n_anchors = len(anchors_inds)\n",
        "\n",
        "print n_anchors\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "356246\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fQV4kEjf7m6Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tpl_model, emb_model = build_model_tpl(Xs[1].shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QOXejW4W7n2-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "NB_EPOCH = 100\n",
        "BATCH_SIZE = 128\n",
        "BIG_BATCH_SIZE = 49000\n",
        "\n",
        "inds = np.arange(n_anchors)\n",
        "\n",
        "def get_batch(hard=False):\n",
        "    batch_inds = np.random.choice(inds, size=BIG_BATCH_SIZE, replace=False)\n",
        "\n",
        "    train_emb = emb_model.predict(x_train, batch_size=1024)\n",
        "    scores = np.matmul(train_emb , train_emb.T)\n",
        "    negative_inds = []\n",
        "\n",
        "    for i in batch_inds:\n",
        "        label = labels[i]\n",
        "        mask = y_train == label\n",
        "        if hard: # picking the closest negative to the anchor\n",
        "            negative_inds.append(np.ma.array(scores[anchors_inds[i]], mask=mask).argmax())\n",
        "        else: # picking randomly\n",
        "            negative_inds.append(np.random.choice(np.where(np.logical_not(mask))[0], size=1)[0])\n",
        "\n",
        "    return anchors[batch_inds], positives[batch_inds], x_train[negative_inds]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NfS1EZ1IEL3t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Training the model each epoch with different set of data as (a,p,n)\n",
        "z = np.zeros((BIG_BATCH_SIZE,))\n",
        "\n",
        "for e in range(1):\n",
        "    a, p, n = get_batch(e > 100)\n",
        "    tpl_model.fit([a, p, n], z, batch_size=BATCH_SIZE, epochs=1, verbose = 0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GUNPTuYDkDF1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c86ea65c-1ca4-4c92-adcd-7082f0dedca3"
      },
      "cell_type": "code",
      "source": [
        "z = np.zeros((BIG_BATCH_SIZE,))\n",
        "a, p, n = get_batch(True)\n",
        "tpl_model.evaluate([a, p, n], z)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49000/49000 [==============================] - 5s 107us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0, 1.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "FSQu7BmnETLp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test_data():\n",
        "    anchors_test_inds = []\n",
        "    positives_test_inds = []\n",
        "    negative_test_inds = []\n",
        "    for subj in subjects:\n",
        "        mask_test = y_test == subj\n",
        "        mask_train = y_train == subj\n",
        "        test_inds = np.where(mask_test)[0]\n",
        "        train_inds = np.where(mask_train)[0]\n",
        "        for p_ in test_inds:\n",
        "            a_ = random.sample(train_inds,1)[0]\n",
        "            anchors_test_inds.append(a_)\n",
        "            positives_test_inds.append(p_)\n",
        "            negative_test_inds.append(np.random.choice(np.where(np.logical_not(mask_train))[0], size=1)[0])\n",
        "\n",
        "\n",
        "    a_test = x_train[anchors_test_inds]\n",
        "    p_test = x_test[positives_test_inds]\n",
        "    n_test = x_train[negative_test_inds]\n",
        "    return a_test, p_test, n_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ag_8VRp2XSZV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "a_test, p_test, n_test = test_data()\n",
        "z = np.zeros((len(a_test),))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_yFNlC_9u1J4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2b5faee8-7275-45bf-b87b-558213e4faf9"
      },
      "cell_type": "code",
      "source": [
        "s = 0\n",
        "c = 0\n",
        "for i in range(len(a_test)):\n",
        "    a_ = emb_model.predict(a_test[i:i+1])\n",
        "    p_ = emb_model.predict(p_test[i:i+1])\n",
        "    n_ = emb_model.predict(n_test[i:i+1])\n",
        "    pos_dist = np.sum(np.square(a_ - p_))\n",
        "    neg_dist = np.sum(np.square(a_ - n_))\n",
        "    c += 1 if pos_dist- neg_dist +.2 > 0 else 0\n",
        "    s += max(0.0,pos_dist- neg_dist+.2)\n",
        "print \"test accuracy: \", 1 - c*1.0/len(a_test)\n",
        "print \"test loss: \", s/len(a_test)\n",
        "    "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test accuracy:  0.97325\n",
            "test loss:  0.0043714195847511204\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "q7NntB5banCS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "model_json = emb_model.to_json()\n",
        "with open('Models/img_emb_model.json', 'w') as json_file:\n",
        "    json_file.write(model_json)\n",
        "emb_model.save_weights('Models/img_emb_model.h5') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kp7ahPWbijo4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
